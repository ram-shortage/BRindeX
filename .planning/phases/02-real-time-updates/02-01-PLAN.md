---
phase: 02-real-time-updates
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Cargo.toml
  - src/lib.rs
  - src/service/config.rs
  - src/indexer/mod.rs
  - src/indexer/usn_monitor.rs
  - src/db/ops.rs
autonomous: true

must_haves:
  truths:
    - "File created on NTFS volume appears in index within 2 polling cycles (60 seconds worst case)"
    - "Service resumes monitoring from last USN on restart without full rescan"
    - "Journal wrap triggers automatic background rescan with warning log"
    - "Rapid file changes deduplicated within batch (only final state persisted)"
    - "Monitoring throttles under heavy CPU load"
  artifacts:
    - path: "src/indexer/usn_monitor.rs"
      provides: "USN Journal polling loop with wrap detection"
      exports: ["UsnMonitor", "poll_changes", "usn_monitor_loop"]
    - path: "src/service/config.rs"
      provides: "TOML configuration with volume settings"
      exports: ["Config", "VolumeConfig", "ExcludeConfig"]
    - path: "src/db/ops.rs"
      provides: "Volume USN state persistence"
      contains: "update_volume_usn"
  key_links:
    - from: "src/indexer/usn_monitor.rs"
      to: "src/db/ops.rs"
      via: "apply_changes_batch calls db insert/update/delete"
      pattern: "apply_file_change"
    - from: "src/service/mod.rs"
      to: "src/indexer/usn_monitor.rs"
      via: "service spawns USN monitor after initial indexing"
      pattern: "usn_monitor_loop"
---

<objective>
Implement NTFS USN Journal monitoring with wrap detection, change deduplication, and configuration management.

Purpose: Keep NTFS volume indexes current by polling the USN Change Journal every 30 seconds, detecting journal wrap, deduplicating rapid changes, and applying batched updates to the database.

Output: Working USN monitor that resumes from last position on service restart, handles journal wrap gracefully, and respects configuration for volume selection and throttling.
</objective>

<execution_context>
@/Users/brett/.claude/get-shit-done/workflows/execute-plan.md
@/Users/brett/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-real-time-updates/02-RESEARCH.md
@.planning/phases/02-real-time-updates/02-CONTEXT.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
@.planning/phases/01-foundation/01-03-SUMMARY.md
@src/db/ops.rs
@src/service/config.rs
@src/indexer/mod.rs
@Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies and TOML configuration infrastructure</name>
  <files>Cargo.toml, src/service/config.rs, src/lib.rs</files>
  <action>
1. Add new dependencies to Cargo.toml:
   - usn-journal-rs = "0.4" for USN Journal access
   - toml = "0.9" for config parsing
   - serde = { version = "1.0", features = ["derive"] } for serialization
   - sysinfo = "0.33" for CPU monitoring
   - directories = "5.0" for standard paths

2. Add Windows features to Cargo.toml target.cfg(windows).dependencies.windows:
   - "Win32_UI_WindowsAndMessaging" (for WM_DEVICECHANGE in Plan 02-02)
   - "Win32_System_SystemInformation" (for system info queries)

3. Expand src/service/config.rs with TOML configuration:
   - Config struct with general, volumes (HashMap), and exclude sections
   - GeneralConfig: data_dir, usn_poll_interval_secs (default 30), offline_retention_days (default 7)
   - VolumeConfig: enabled (bool), reconcile_interval_mins (default 30)
   - ExcludeConfig: paths (Vec<String>), extensions (Vec<String>)
   - load() and save() methods using toml crate
   - config_path() returning %PROGRAMDATA%\FFI\config.toml (use directories crate)
   - Default impl creating sensible defaults

4. Add ConfigError variant to FFIError in src/lib.rs

Follow RESEARCH.md Pattern 4 for TOML configuration structure.
  </action>
  <verify>cargo check passes; Config::default() creates valid config; Config::load/save roundtrip works</verify>
  <done>Configuration infrastructure complete with TOML serialization and standard paths</done>
</task>

<task type="auto">
  <name>Task 2: Implement USN Journal monitor with wrap detection</name>
  <files>src/indexer/usn_monitor.rs, src/indexer/mod.rs, src/db/ops.rs</files>
  <action>
1. Create src/indexer/usn_monitor.rs with:

   UsnMonitor struct:
   - volume: Drive letter (char)
   - last_usn: i64 (last processed USN)
   - journal_id: u64 (for wrap detection)

   Methods:
   - new(drive_letter: char) -> Result<Self>: Opens USN journal, queries metadata, stores journal_id and FirstUsn as starting point
   - poll_changes(&mut self) -> Result<Vec<UsnChange>, UsnError>:
     * Query current journal metadata
     * Check journal_id matches (if not, return JournalRecreated error)
     * Check last_usn >= LowestValidUsn (if not, return JournalWrapped error)
     * Read changes from last_usn using iter_from()
     * Update last_usn to latest record's USN
     * Return Vec of UsnChange structs

   UsnChange struct:
   - file_ref: i64
   - parent_ref: i64
   - name: String
   - change_type: ChangeType (Create, Delete, Rename, Modify)

   UsnError enum:
   - JournalNotActive (fallback to FAT-style periodic scan)
   - JournalWrapped (trigger background rescan)
   - JournalRecreated (trigger background rescan)
   - Other(String)

2. Add change deduplication function deduplicate_changes():
   - Use HashMap<i64, ChangeType> keyed by file_ref
   - Later changes override earlier ones
   - Create then Delete = remove from map entirely
   - Return Vec of final states

3. Add apply_changes_batch() function:
   - Takes db connection, volume_id, Vec<(file_ref, ChangeType, UsnRecord)>
   - Single transaction for all changes
   - INSERT OR REPLACE for Create
   - DELETE for Delete
   - UPDATE name/parent for Rename
   - UPDATE size/modified for Modify

4. Extend src/db/ops.rs:
   - update_volume_usn(conn, volume_id, last_usn, journal_id) for persistence
   - get_volume_usn(conn, volume_id) -> Option<(last_usn, journal_id)> for resume
   - Add last_usn and journal_id columns to volumes table schema (src/db/schema.rs)

5. Export module in src/indexer/mod.rs

Use #[cfg(windows)] to gate Windows-only code, provide stub for non-Windows.
Follow RESEARCH.md Pattern 1 for polling loop and Pattern 2 for wrap detection.
  </action>
  <verify>cargo check passes; UsnMonitor::new() compiles; deduplicate_changes removes create-then-delete pairs</verify>
  <done>USN monitor compiles with wrap detection and change deduplication logic</done>
</task>

<task type="auto">
  <name>Task 3: Wire USN monitor loop with adaptive throttling</name>
  <files>src/indexer/usn_monitor.rs, src/indexer/mod.rs, src/service/mod.rs</files>
  <action>
1. Add AdaptiveThrottle struct to src/indexer/usn_monitor.rs:
   - system: sysinfo::System
   - normal_interval: Duration (from config, default 30s)
   - throttled_interval: Duration (4x normal when under load)
   - cpu_threshold: f32 (80.0%)

   Methods:
   - new(normal_secs: u64) -> Self
   - get_interval(&mut self) -> Duration: Refresh CPU, return throttled if > threshold

2. Add usn_monitor_loop() function:
   - Parameters: volume_letter, db_path, config, shutdown_rx: Receiver<()>
   - Create UsnMonitor for volume
   - Load last_usn from database (resume point)
   - Loop:
     * Check shutdown_rx.try_recv() for exit signal
     * Get adaptive interval based on CPU load
     * Call poll_changes()
     * On success with changes: deduplicate, apply_changes_batch, update_volume_usn
     * On JournalWrapped/Recreated: log warning, trigger_background_rescan()
     * On JournalNotActive: log info, break loop (treat as FAT volume)
     * Sleep for interval

3. Add trigger_background_rescan() placeholder:
   - Logs "Background rescan triggered for volume X"
   - TODO: Will be implemented fully when integrated with indexer

4. Update src/indexer/mod.rs:
   - Add start_usn_monitors() function that spawns monitor thread per NTFS volume
   - Only start after initial indexing completes (per CONTEXT.md decision)
   - Pass shutdown channel to each monitor

5. Update src/service/mod.rs:
   - After initial indexing completes, call start_usn_monitors()
   - Pass config for poll intervals
   - Wire shutdown signal to USN monitors

Gate all Windows code with #[cfg(windows)]. Non-Windows returns immediately.
Follow RESEARCH.md Pattern 5 for adaptive throttling.
  </action>
  <verify>cargo check passes; cargo build --release succeeds; service compiles with USN monitor integration</verify>
  <done>USN monitoring wired to service lifecycle with adaptive throttling and graceful shutdown</done>
</task>

</tasks>

<verification>
1. cargo check passes with no errors
2. cargo build --release succeeds
3. cargo test passes (if tests added)
4. Config file parses correctly from TOML
5. USN monitor compiles and integrates with service lifecycle
6. Adaptive throttling logic correctly identifies high CPU (manual inspection)
</verification>

<success_criteria>
- Dependencies added: usn-journal-rs, toml, serde, sysinfo, directories
- Config infrastructure loads/saves TOML with volume settings
- UsnMonitor polls journal and detects wrap conditions
- Change deduplication removes redundant operations
- Service spawns USN monitors after initial indexing
- Monitors throttle under high CPU load
- All code compiles on Windows and non-Windows (conditional compilation)
</success_criteria>

<output>
After completion, create `.planning/phases/02-real-time-updates/02-01-SUMMARY.md`
</output>
